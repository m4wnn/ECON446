{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3604af7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<script src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988e89",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <h1>Webscraping</h1>\n",
    "    <h4>Applications of Cloud Computing and Big Data - ECON 446</h3>\n",
    "    <div style=\"padding: 20px 0;\">\n",
    "        <hr style=\"border: 0; height: 1px; background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));\">\n",
    "        <p><em>Mauricio Vargas-Estrada</em><br>\n",
    "        Master Of Quantitative Economics<br>\n",
    "        University of California - Los Angeles</p>\n",
    "        <hr style=\"border: 0; height: 1px; background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caecd454",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Web Scraping Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaae8c8",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       a.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Create a list of links for all the wikipedia pages for NYSE traded companies A-Z and 0-9.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccde02a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import string\n",
    "import toolz\n",
    "import pandas as pd\n",
    "from rich import inspect\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65204745",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "url = lambda x: f'https://en.wikipedia.org/wiki/Companies_listed_on_the_New_York_Stock_Exchange_({x})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f82802",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_table_info(soup):\n",
    "    links = []\n",
    "    names = []\n",
    "    tickers = []\n",
    "\n",
    "    # For each row in the table of companies.\n",
    "    for r in soup.find_all('tr'):\n",
    "        # Get the columns for the row `r`.\n",
    "        row = r.find_all('td')\n",
    "        # Check if the row contains data.\n",
    "        if row:\n",
    "            # Extract the link of the company in the row `r`.\n",
    "            tmp_link = row[0].find_all('a')\n",
    "            # Check if the company has a link.\n",
    "            if tmp_link:\n",
    "                names.append(tmp_link[0].text)\n",
    "                # Adding the root to the relative path.\n",
    "                links.append('https://www.wikipedia.org' + tmp_link[0].get('href'))\n",
    "                tickers.append(row[1].text.strip())\n",
    "    return names, tickers, links        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "names = []\n",
    "tickers = []\n",
    "for letter in tqdm(list(string.ascii_uppercase) + ['0-9']):\n",
    "    req = requests.get(url(letter), headers=headers, timeout=20)\n",
    "    # Pass if the request is not successful or time out.\n",
    "    if not req.ok:\n",
    "        continue\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    tmp_n, tmp_t, tmp_l= get_table_info(soup)\n",
    "    links.extend(tmp_l)\n",
    "    names.extend(tmp_n)\n",
    "    tickers.extend(tmp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24905206",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "companies = pd.DataFrame({'company': names, 'ticker': tickers, 'link': links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f59937",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#companies.to_csv('data/companies_links.csv', index=False)\n",
    "#companies = pd.read_csv('data/companies_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e9b61",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       b.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Crawl through all the URLs and make 1 DF with all the NYSE publically traded companies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd0386",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       c.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        What is the percetages of companies that contain 1 letter, 2 letters, 3 letters, 4 letters, 5 letters,... in the ticker (drop punctuation)?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d97d8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Web Scraping Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b359afbe",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       a.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Using Beautiful soup .findAll method you will webscrape the front page of Reddit. Get a list of all of the \"timestamps\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc666a69",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "URL = \"https://www.reddit.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84c5d3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       b.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Using the functions findChild, descendents, etc. locate the post title, text and post time into a dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90f56f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67f160",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       a.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Using RegEx, get all the urls of ladder faculty profiles for UCLA Economics\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa443f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "URL = \"https://economics.ucla.edu/faculty/ladder\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201c24e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       b.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Webcrawl the links from A and use RegEx to get all the emails and phone numbers of ladder faculty profiles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51e5be",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875d32b",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       a.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Pick a website that has useful data to a business or economic question. Put your website you plan to scrape here : \n",
    "        \n",
    "        https://docs.google.com/spreadsheets/d/1PJ2DOTCVCh51fn0ry1yB7qTyccR33_IXFpkYdd58MFs/edit?usp=sharing\n",
    "\n",
    "        You must have use website that no other group has. First come first serve.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d00f7a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       b.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Use Selenium to scrape valuable information from your website and store in a dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac15cb",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black; border-radius: 5px; overflow: hidden;\">\n",
    "    <div style=\"background-color: black; color: white; padding: 5px; text-align: left;\">\n",
    "       c.) \n",
    "    </div>\n",
    "    <div style=\"padding: 10px;\">\n",
    "        Write a short paragraph about the businesses or research that would use the data you scraped. Describe it's value and what it can be used for.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
